# Οπτικοποίηση της Πληροφορίας

>> Μπορείτε να βρείτε τον πηγαίο κώδικα για τον παρακάτω πίνακα στο κουμπί `Raw` και μετά να τον αντιγράψετε στην αναφορά σας ως πίνακα περιεχομένων με σύνδεσμο προς τις υποενότητες-δραστηριότητες κάθε εβδομάδας.

| Εβδομάδα* | Παραδοτέο | Σύνδεσμος στην [εβδομαδιαία παρουσίαση προόδου στις συζητήσεις](https://github.com/upatras-hci/iv/discussions/categories/show-and-tell) | Αυτοαξιολόγηση σύμφωνα με τα κριτήρια της αντίστοιχης άσκησης |
| --- | --- | --- | --- |
| 1 | [Δημιουργία ομάδας](https://courses-ionio.github.io/help/team/) + [Φορκ και δημιουργία σελίδας τελικής αναφοράς](https://courses-ionio.github.io/help/guide/), [προσθήκη πίνακα περιεχομένων](https://raw.githubusercontent.com/upatras-hci/iv/master/README.md), [συγγραφή της εισαγωγής](https://courses-ionio.github.io/help/intro/), αποστολή της εισαγωγής [για σχολιασμό στην συζήτηση](https://github.com/upatras-hci/iv/discussions/categories/show-and-tell) και καταγραφή του συνδέσμου συζήτησης δίπλα --> |[CV introduction](https://github.com/upatras-hci/iv/discussions/35)| | 
| 2 | βιογραφικό Α | [CV A](https://evangeliachatz.github.io/online-cv/)  |
| 3 | γραμμή εντολών (arch linux) |[Arch Linux Virtual Box Installation](https://asciinema.org/a/YxVWdKOGY5LTYak37pSUJafmi)||
| 4 | συμμετοχικό 1A | [Text-to-image](https://github.com/upatras-HCI-2022/site/pull/3/commits/10e1158ffa8c4013c05efaf20c64de13eef6facc) & [Riffusion](https://github.com/upatras-HCI-2022/site/pull/27)| |
| 5 | γραμμή εντολών (custom desktop environment) |[polybar](https://drive.google.com/file/d/18SxKvZ-IzT-Xss-jgpNVzpHGr_K6tr-J/view?usp=share_link) [pipes](https://asciinema.org/a/PrZft1RuUiJ1qmK9Q0C0scVBY) [VLC Installation](https://drive.google.com/file/d/1IWxuuzfntMdKXpGIWwjdqOwJX019WWOU/view?usp=share_link)| |
| 6 | συμμετοχικό περιεχόμενο 2Α | [1st interactive example](https://wondrous-paletas-7dd991.netlify.app/remix/signupform/),[2nd interactive example](https://wondrous-paletas-7dd991.netlify.app/remix/animated-tab-bar/)| |
| 7 | βιογραφικό Β |[CV B](https://evangeliachatz.github.io/simple-cv/) | |
| 8 | γραμμή εντολών (iv cli) |[pastel package](https://asciinema.org/a/Jo6RRXTym6GYFDs1A3S39tEcz) | |
| 9 | συμμετοχικό περιεχόμενο 1Β |[Case Study-Voice chess Challenger](https://wondrous-paletas-7dd991.netlify.app/case-study/voice-chess-challenger/),[Biography-Dudley Homer](https://wondrous-paletas-7dd991.netlify.app/biography/homer-dudley/) | |
| 10 | γραμμή εντολών (iv cli) |[icons-in-terminal package](https://asciinema.org/a/9JSwQZbRVRszRvT5XDb9FItZQ) | |
| 11 | συμμετοχικό περιεχόμενο 2Β |Not delivered | |
| 12 | Τελική αναφορά* | | |



## Personal Information
![bigger2](https://user-images.githubusercontent.com/99615706/219009683-961cb9bd-0dba-4ee8-b800-8ff0d218ea11.svg)
 </br>
Name: Chatzilygeroudi Evangelia </br>
ΑΜ: 1018865




## 1. ![cv icon](https://user-images.githubusercontent.com/99615706/219009819-626d7744-6367-4699-b05e-11e63b4d426f.svg) Introduction & Organization Set up

My name is Chatzilygeroudi Evangelia.
I used to work in finance , after my bachelor at [Department of Economics](https://www.econ.upatras.gr/el), but after many years of interaction with arts, jewelry(3D design) and make designs for friends and work, I discovered that design is my passion. </br>


</br>
I have been studying for six months, User Experience Design at [SAE Institute](https://www.sae.edu/grc/), so that I can make my designs beautiful and easy to use. At SAE Institute, I have had the chance to get to know the process (UX
Competitive Analysis, Neilsen Heuristics, User Interviews, Usability Testing,
Information Architecture, Navigation Design, Wireframes/Prototypes &
Design System) of User Centered Design, where I was introduced the
importance of analyzing the user’s behavior and use them at the design.
Now, I'm working at an Agency as UI/UX Designer.</br>

In addition, it’s in my plans to develop my skills in Front End programming
(HTML, CSS, Javascript).</br>

I decided to choose this course, because I would have the opportunity to expand my knowledge  and learn how the information is visualized correctly, which is part of my job. </br>

![Frame 99 (2)](https://user-images.githubusercontent.com/99615706/219007192-0c59a825-4236-481d-85f2-97c2e8986a5e.svg)




### Organization creation & webring
In this part of the lesson we the [Human - Computer Interaction 2022 - 2023 Organisation](https://github.com/upatras-HCI-2022), and the [webring of our team](https://upatras-hci-2022.github.io/webring/) , too.There is the [repository](https://github.com/upatras-HCI-2022/webring) of it.



## 2.CV Site-Convert Yaml file to Site
At first,we wanted to create an online site that CV ,will to created automatically from a [yaml](https://github.com/EvangeliaChatz/online-cv/blob/gh-pages/_data/data.yml) file,  using Jekyll.  <br />
I create a branch.

| Link onlive CV | My CV repository | Link of initial repository |
| --- | ----------- | --- |
| [CV Site](https://evangeliachatz.github.io/online-cv/) | [repository](https://github.com/EvangeliaChatz/online-cv) | [repository origin](https://github.com/sharu725/online-cv)|



## 3.Command Line -ArchLinux Installation
Firsty, I tried to install Arch Linux with USB, but I couldn't input characters in terminale
So the installation was repeated in Virtual Box. </br> 
I followed the below steps: </br>

#### 🔗 [Installation of powerline](https://github.com/powerline/powerline) <br>
1️⃣ Install powerline & powerline-fonts packages with sudo pacman:
```sh
sudo pacman -S powerline
``` 
2️⃣ Add the following lines to ~/.bashrc file in order to enable powerline:
```sh
vim .bashrc
``` 
3️⃣ Powerline-deamon -q #if this line creates error remove it

4️⃣ Finally, source .bashrc, or close and reopen Terminal
sudo pacman -S powerline powerline-font
```sh
sudo pacman -S powerline powerline-fonts
``` 
5️⃣ I Opened the .bashr file and erase the # to make them active
</br>

![SCREENSHOT SVG](https://user-images.githubusercontent.com/99615706/218861865-9e4d0507-3d0f-4966-9009-28b318400fe9.svg)| ![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg)
-------------------------|-------------------------
![](https://user-images.githubusercontent.com/99615706/218537716-806954fc-6731-4fdc-9160-a6da8a9e280a.png)|[![asciicast](https://asciinema.org/a/j9Q86Tlig0Is8ZLlA6InJVfQx.svg)](https://asciinema.org/a/j9Q86Tlig0Is8ZLlA6InJVfQx)
<br>


#### 🔗 [Neofetch Installation](https://asciinema.org/a/YxVWdKOGY5LTYak37pSUJafmi) <br>
Neofetch is a tool that allows us to get basic information about the installed system. It is the ideal tool to learn at a glance the basic features of the installed operating system. We can install it very simply by running the command:</br>
1️⃣ Downolad neofetch package with:
```sh
sudo pacman -S neofetch
``` 
2️⃣ And run neofetch:
```sh
neofetch
``` 
</br>

![SCREENSHOT SVG](https://user-images.githubusercontent.com/99615706/218861865-9e4d0507-3d0f-4966-9009-28b318400fe9.svg)| ![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg)
-------------------------|-------------------------
![space-1.jpg](https://user-images.githubusercontent.com/99615706/218537213-8f42f424-0b3c-47c5-bf6f-33b1aa3ee59d.png)*ArchLinux installation*|[![video neofetch](https://asciinema.org/a/YxVWdKOGY5LTYak37pSUJafmi.svg)](https://asciinema.org/a/YxVWdKOGY5LTYak37pSUJafmi)


#### 🔗 [Solarized Installation](https://github.com/altercation/solarized) <br>
1️⃣ Download solarized package. There you will fine a file with name: solarized.vim:</br>
2️⃣ Move solarized.vim to ~/.vim/colors folder, if no exist create the folders using mkdir </br>
3️⃣ If you have no permissions to make that move, do it as a root </br>
4️⃣ To become root type: sudo -i </br>
5️⃣ Then create a vim file with name '.vimrc' on /home folder and place the below </br>
```sh
syntax enable set background=dark colorscheme solarized
``` 
6️⃣ From now the vim file will open with solarized theme.</br>

![SCREENSHOT SVG](https://user-images.githubusercontent.com/99615706/218861865-9e4d0507-3d0f-4966-9009-28b318400fe9.svg)| ![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg)
-------------------------|-------------------------
![space-1.jpg](https://user-images.githubusercontent.com/99615706/218537509-d8880dcd-47f4-45e8-8b8b-67e1c9aec1d3.png)*Solarized installation*|[![asciicast](https://asciinema.org/a/ed4oDeeBTOMuU5kxnJmNhgUZN.svg)](https://asciinema.org/a/ed4oDeeBTOMuU5kxnJmNhgUZN)







## Participatory content 1Α1-Two images with caption

For participant 1A1, firstly I added the four images(two for each theme-one little and a bigger one) in [my image's repository](https://github.com/EvangeliaChatz/images-hci-2022) and then I created two separate `md files`, one for each image([`text-to-image.md`](https://github.com/EvangeliaChatz/_gallery-hci-2022/blob/master/text-to-image.md) & [`rifussion.md`](https://github.com/EvangeliaChatz/_gallery-hci-2022/blob/master/riffussion.md)), in [my gallery's repository](https://github.com/EvangeliaChatz/_gallery-hci-2022). Gallery and Images repositories are forked from organization's ones. Secondly, I made a pull request to the organization's repository, which are shown in the table at the end of the section.
<br>



About this delivered, we decided all together that we will place content, regarding to how the art 🎨 is highlighted.</br>
![IMAGE 1](https://user-images.githubusercontent.com/99615706/218914126-25cba623-9de5-4af6-9dec-2055fcef8aee.svg)| ![IMAGE 2](https://user-images.githubusercontent.com/99615706/218914154-8eb5c078-56e1-42b4-b081-36ddeaef08e4.svg)
-------------------------|-------------------------
![IMAGE1.jpg](https://user-images.githubusercontent.com/99615706/218826776-57a5bb03-4d86-4064-bd9b-c0298ad0d3e4.png)*<sup> The license terms of the photo can be found [here](https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE)</sup>*|![IMAGE1.jpg](https://user-images.githubusercontent.com/99615706/218541273-bf85caa3-af85-4612-b6eb-a7d047692165.png)*<sup> The license terms of the photo can be found [here](https://github.com/riffusion/riffusion/blob/main/LICENSE)</sup>*| 


#### Image1
[Text to Image AI](https://deepai.org/machine-learning-model/text2img) is technology that converts text to Pictures/Images, using AI algorithms. The AI models are feed with a huge amount of pictures/images with a simple description in order to be trained on converting text to images. These algorithms even if they can generate AI art, unreal images or funny paradox pictures,
there is a lot of lack of photorealism in most of the results. Of course there are huger and more clever text-to-image generator
but are not free to use.
The photo caption was created with the use of free Internet software `"DeepAI"`, a Text To Image - AI Image Generator
and using "Dancing Animals" as input the input text.
</br>

#### Image2
[Riffusion](https://www.riffusion.com/) is a type of artificial neural network that generates music by utilizing images of sound instead of audio. It was created by Seth Forsgren and Hayk Martiros and is based on [Stable Diffusion](https://github.com/Stability-AI/stablediffusion), a pre-existing open-source model for generating images from text prompts. Riffusion takes these image files and converts them into audio files by running them through an inverse Fourier transform. Although the generated audio files are only a few seconds long, Riffusion has the ability to interpolate different files together by using the latent space between outputs and a functionality of Stable Diffusion known as img2img.
Riffusion has been described as "out of this world" music, but is unlikely to replace traditional music created by humans. The code for Riffusion was released on December 15, 2022 and is available on GitHub. It is one of several models derived from Stable Diffusion and falls within the subset of AI text-to-music generators. Other similar models include Mubert, which was released in December 2022 and used Stable Diffusion to turn descriptive text into music loops, and Google's MusicLM, which was published in January 2023.
Riffusion has been described as "out of this world" music, but is unlikely to replace traditional music created by humans. The code for Riffusion was released on December 15, 2022 and is available on GitHub. It is one of several models derived from Stable Diffusion and falls within the subset of AI text-to-music generators. Other similar models include Mubert, which was released in December 2022 and used Stable Diffusion to turn descriptive text into music loops, and Google's MusicLM, which was published in January 2023. 
</br>


 | Images(my image's repository) | Images Pull request | Gallery Pull request  |
| --- | --- | ----------- |
|[image1-text-to-image](https://github.com/EvangeliaChatz/images-hci-2022/blob/master/text-to-image.jpeg) | [image1-pull request](https://github.com/upatras-HCI-2022/images/pull/10) | [text-to-image pull request](https://github.com/upatras-HCI-2022/_gallery/pull/22) |
|[image2-riffussion](https://github.com/upatras-HCI-2022/images/blob/master/riffussion.png)|[image2-pull request](https://github.com/upatras-HCI-2022/images/pull/18) | [rifussion pull request](https://github.com/upatras-HCI-2022/_gallery/pull/23) |
</br>




## 4.Participatory content 1Α2-Slides and Timeline
For the participatory content 1A2 we added as an [organization](https://github.com/upatras-HCI-2022), an [`art.md` file1](https://github.com/upatras-HCI-2022/site/blob/master/_slides/art.md) for the slides, and  an [`art.md` file2](https://github.com/upatras-HCI-2022/site/blob/master/_timeline/art.md) for timeline, on [site's repository](https://github.com/upatras-HCI-2022/site), in the [slides folder](https://github.com/upatras-HCI-2022/site/tree/master/_slides) and in [timeline folder](https://github.com/upatras-HCI-2022/site/tree/master/_timeline), respectively, from file which will gather all the images with their descriptions at organization's [repository](https://github.com/upatras-HCI-2022/site). </br> 

| Pull request | Pibook link | Organization's pibook links |
| --- | ----------- | ----------- |
| [Dancing animals](https://github.com/upatras-HCI-2022/site/pull/3) | [pibook slides](https://wondrous-paletas-7dd991.netlify.app/slides/art/) | [all images together](https://wondrous-paletas-7dd991.netlify.app/slides/art/)
| [Riffusion](https://github.com/upatras-HCI-2022/site/pull/27) | [pibook timeline](https://wondrous-paletas-7dd991.netlify.app/timeline/art/) | [timeline](https://wondrous-paletas-7dd991.netlify.app/timeline/art/)|

</br>



## 5.Custom Desktop Enviroment
For command line usage I installed a simple [window manager]( https://courses-ionio.github.io/help/cli/).
I also installed the following packages:The Polybar font is package with default status bar.I tried the `hack` theme. Polybar package is for add to our desktop a status bar that shows information relative to CPU usage, RAM usage, information about connection, volume. The second package is a screensaver, fills it with moving images or patterns when the computer has been idle for a designated time.The third one, is the well known, VLC Player.
</br>

|![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg)| ![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg) |![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg)|
|-------------------------|                                                                                       -------------------------                                                                                            | -------------------------|
|![Polybar_Installation](https://user-images.githubusercontent.com/99615706/218886474-056572c0-532a-466b-863e-c44847729132.gif)*Polybar Installation*|[![asciicast](https://asciinema.org/a/PrZft1RuUiJ1qmK9Q0C0scVBY.svg)](https://asciinema.org/a/PrZft1RuUiJ1qmK9Q0C0scVBY)*Pipes* | ![VLC_Installation](https://user-images.githubusercontent.com/99615706/218886622-ba347e03-cd68-4dcd-a124-35440204db67.gif)*VLC Player* |
|<sup>Sorry, for the videos that keep playing, just needed to show the full screen to show the custom enviroment elements</sup> | |


                   
                   
                   
## 6.Participatory content 2Α-Interactive examples
For this deliverable, I created two files called, [`animated-tab-bar.md`](https://github.com/EvangeliaChatz/site-hci-2022/blob/master/_remix/animated-tab-bar.md) & [`signupform.md`](https://github.com/EvangeliaChatz/site-hci-2022/blob/master/_remix/signupform.md) in the [remix folder](https://github.com/EvangeliaChatz/site-hci-2022/tree/master/_remix) in my [site's repository](https://github.com/EvangeliaChatz/site-hci-2022/tree/master) and make pull request to [organization's site repository](https://github.com/EvangeliaChatz/site-hci-2022/tree/master/_remix).Pull request are in the table at the end of the section.<br>
As a designer, I decided that the changes from the [initial one](https://codepen.io/ehermanson/details/KwKWEv) I will make to the exercises have to do with improving the UI so I chose the following interactive examples:</br>

#### 🔗 [Sign up/Sign in form](https://codepen.io/EvangeliaChatz/pen/GRBXNPd)  <br>
In this example I made changes such as changing the font sizes,from the [initial one](https://codepen.io/ehermanson/pen/KwKWEv) as they were too large and spoiled the final result. </br>
Change in focus state, when the user clicks on a form field to fill it, and other minor changes seen in the code. In more detail I did the followings:
<br>

 ![BEFORE](https://user-images.githubusercontent.com/99615706/218907604-e371fb6e-880e-4b55-8678-927619219d9f.svg)| ![AFTER](https://user-images.githubusercontent.com/99615706/218907639-221f624f-b176-47ff-847b-a4e52c9ca3c9.svg)
-------------------------|-------------------------
<img width="364" alt="image" src="https://user-images.githubusercontent.com/99615706/218907127-d9d064e8-8cf1-439e-a043-7ffdf99ef9c2.png">|<img width="368" alt="image" src="https://user-images.githubusercontent.com/99615706/218907203-f123e208-da5e-4bf1-af72-bfb598d521dc.png">
  <sup> Exercise: Modify the form to have other colors</sup>
 


#### 🔗 [Animated tab bar](https://codepen.io/EvangeliaChatz/pen/YzjdrGm) <br>
In this example I made changes also changes,from the [initial one](https://codepen.io/abxlfazl/pen/VwKzaEm), that are the changes below: <br> 
1️⃣ I added comments to better show where the icons are <br>
2️⃣ I zoomed out and changed the icons <br>
3️⃣ I rounded the edges <br>
4️⃣ I increased the height because with the smaller icons it was short <br>
5️⃣ I added the commands <br>
6️⃣ I changed the font to Poppins by inserting `@import url('https://fonts.googleapis.com/css2?family=Arimo&family=Inter&family=Poppins&display=swap’);` into the css <br>
<br>

 ![BEFORE](https://user-images.githubusercontent.com/99615706/218907604-e371fb6e-880e-4b55-8678-927619219d9f.svg)| ![AFTER](https://user-images.githubusercontent.com/99615706/218907639-221f624f-b176-47ff-847b-a4e52c9ca3c9.svg)
-------------------------|-------------------------
<img width="397" alt="image" src="https://user-images.githubusercontent.com/99615706/218908017-c2d70f92-2fc0-4dc9-b159-14e18c2a21c3.png">|<img width="392" alt="image" src="https://user-images.githubusercontent.com/99615706/218907973-410d7f8a-ac23-44a6-b819-e61d3e6032d4.png">
<sup>Exercise: Change the icons and format of the tab bar.</sup>


<br>

| Interactive examples | Pull request | Organization's pibook links |
| --- | ----------- | ----------- |
| Sign up form | [sign up-sign in form-pull request](https://github.com/upatras-HCI-2022/site/pull/12) | [sign up form link](https://wondrous-paletas-7dd991.netlify.app/remix/signupform/)
| Animated tab bar | [animated tab bar pull-request](https://github.com/upatras-HCI-2022/site/pull/18) | [animated tab bar link](https://wondrous-paletas-7dd991.netlify.app/remix/animated-tab-bar/)|

## 8.Command line1 (iv cli)
In this exercise I used the [pastel](https://github.com/sharkdp/pastel) from [available](https://github.com/epidrome/dokey) command from the available command line exercises.This package uses colors to enhance the CLI (Command Line Interface), that is, it prints colored texts to make them more beautiful and recognizable. I followed the repository instructions carefully.
Pastel is a command line tool for creating and editing colors in terminal applications. On Arch Linux, you can use Pastel to perform the following tasks: </br>
1️⃣ Generate color codes in various formats (e.g., RGB, HEX, ANSI). </br>
2️⃣ Apply color to text and background. </br>
3️⃣ Create color palettes. </br>
4️⃣ Change colors (e.g., lighten, darken, saturate). </br>
5️⃣ Display color information (e.g. RGB values, HEX codes, ANSI codes). </br>
6️⃣ These tasks can be performed with the various subcommands of the Pastel package. </br>
I used some of them above: </br>

1️⃣ Install pastell package:
```sh
sudo pacman -S pastel
``` 

For my work I use color code switching every day. For example, in this one I'm converting a #hex color to rgb:<br>
2️⃣ Generate color codes in various formats:
```sh
pastel color c837ca | pastel format rgb
``` 

The ability to find the complement of each color is also very useful:<br>
3️⃣ Generate the complement color:
```sh
pastel color c837ca | pastel complement
```

You can easily choose any color from the entire color spectrum:<br>
4️⃣ Pick a color:
```sh
pastel pick
```

Ι use color to improve the cli tools: <br>
5️⃣ Print colorized text from a shell script, in order to make it more beautiful-usable:
```sh
pastel paint -n black --on red --bold "EXAMPLE"
```
</br>

The above commands are shown in the video below: </br>


![SCREENSHOT SVG](https://user-images.githubusercontent.com/99615706/218861865-9e4d0507-3d0f-4966-9009-28b318400fe9.svg)| ![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg)
-------------------------|-------------------------
![space-1.jpg](https://user-images.githubusercontent.com/99615706/218538850-1f38dcc0-8e00-4e80-b6ec-f00f47594890.png)*Pastel Package*|[![asciicast](https://asciinema.org/a/Jo6RRXTym6GYFDs1A3S39tEcz.svg)](https://asciinema.org/a/Jo6RRXTym6GYFDs1A3S39tEcz)



## 10.Command line2 (iv cli)
The second command line exercise I've done is icons-in-terminal:

1️⃣ Make a clone of icons-in-terminal:
```sh
$ git clone https://github.com/sebastiencs/icons-in-terminal.git
```
<br>
When I close the terminal and open it again, icons like screenshot below, appeared.

![SCREENSHOT SVG](https://user-images.githubusercontent.com/99615706/218861865-9e4d0507-3d0f-4966-9009-28b318400fe9.svg)| ![VIDEO SVG](https://user-images.githubusercontent.com/99615706/218868273-84e63032-f154-4339-9b81-c07ab26e1e5c.svg)
-------------------------|-------------------------
![space-1.jpg](https://user-images.githubusercontent.com/99615706/218669485-df8e36ec-bca1-4208-8d1f-e7990f95f877.png)*Icons in terminal package*|[![asciicast](https://asciinema.org/a/9JSwQZbRVRszRvT5XDb9FItZQ.svg)](https://asciinema.org/a/9JSwQZbRVRszRvT5XDb9FItZQ)





## 9.Participatory content 1B-Case Study & Biography
This deliverable has two [parts](https://courses-ionio.github.io/help/social/). One is about a case study and the second one is a biography.<br>
I added two `md files`, in [includes folder](https://github.com/upatras-HCI-2022/site/tree/master/_includes) of [organization's site repository](https://github.com/upatras-HCI-2022/site), which are [`cs-voice-chess-challenger.md`](https://github.com/EvangeliaChatz/site-hci-2022/blob/master/_includes/cs-voice-chess-challenger.md) & [`bio-dudley.md`](https://github.com/EvangeliaChatz/site-hci-2022/blob/master/_includes/bio-dudley.md), respectively.<br>
Also, two `md files` added to [case study](https://github.com/upatras-HCI-2022/site/tree/master/_case-study) & [biography](https://github.com/upatras-HCI-2022/site/tree/master/_biography) folders, which are [`voice-chess-challenger.md`](https://github.com/upatras-HCI-2022/site/blob/master/_case-study/voice-chess-challenger.md) & [`homer-dudley.md`](https://github.com/upatras-HCI-2022/site/blob/master/_biography/homer-dudley.md).The `md files` contained the photos that are displayed on the site of the Organizatio, so I added the photos required.



#### Case Study
Having dealt with software that converts text into image and music respectively, I decided to explore the field that converts speech into movements, and the wider field of voice recognition. </br>
In the first part (participatory 1B1), Voice Chess Challenger, developed in the 1970s, was one of the first examples of using voice interaction to play a game. The device used speech recognition technology to recognize voice commands and control the chessboard, allowing players to make moves by speaking into a microphone. This early application of speech recognition demonstrated the possibility of using voice commands to interact with electronic devices and helped lay the foundations for the development of modern speech recognition systems. It then takes a historical look back at the development of this industry, and examples of similar games are cited , based on voice recognition. </br>


#### Biography
In the second part, I looked into the same field and referred to the biography of one of the contributors to the history of voice recognition, Dudley Homer. Homer Dudley was an American electrical engineer and a pioneer in the field of speech recognition. Dudley is best known for his work to Vocoder1, an engine that analyzed and synthesized speech. Vocoder was one of the first speech recognition systems and helped lay the foundation for modern speech recognition technology. </br>


Images Pull request|  Site Pull requests | Pibook link |
| ---| --- | ----------- |
[case study photos](https://github.com/upatras-HCI-2022/images/pull/12)| [Case study](https://github.com/upatras-HCI-2022/site/pull/28) | [Case study](https://wondrous-paletas-7dd991.netlify.app/case-study/voice-chess-challenger/) |
[biography photos](https://github.com/upatras-HCI-2022/images/pull/15)| [Biography](https://github.com/upatras-HCI-2022/site/pull/22) | [Biography](https://wondrous-paletas-7dd991.netlify.app/biography/homer-dudley/) |


## 7.CvB-Convert Yaml file to PDF
For this deliverable,I made a `git clone` (with ArchLinux command line) of the repository [simple-cv](https://github.com/plain-plain-text/simple-cv) referring to [pronunciation](https://courses-ionio.github.io/help/cv/) of exercise. After installing pandoc & latex, I ran the process file to convert it to pdf. The above steps can be seen in the following asciinema. Also to update the changes every time I ran the command sh process.sh. <br>
[![asciicast](https://asciinema.org/a/AyARrivlbN1rfJdCAfLY0Ku0R.svg)](https://asciinema.org/a/AyARrivlbN1rfJdCAfLY0Ku0R) <br>that generates a [pdf file](https://evangeliachatz.github.io/simple-cv).In order to change the elements in the pdf file, I had to change the md files.Also, to upload the changes I make each time to a file in the repository, I following the following instructions: `git add.`, `git commit` and finally `git push`. Then, a workflow must be created to make the changes automatically when a git push was made(Continous Integration). </br>
Finally, I understand that this template don't generate pdf from yaml and I decided to make another one call [resume-template](https://github.com/EvangeliaChatz/resume-template) , but haven't finish yet.Next steps:activate github actions to make a workflow that renders and commits a PDF every time a change is done on the repository, change [yaml files](https://github.com/EvangeliaChatz/resume-template/tree/gh-pages/_data) with my personal information.This deliverable haven't finish yet.

<br>
Thank you for your time!


## 11.Participatory content 2B

Not delivered


